{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca20e742",
   "metadata": {},
   "source": [
    "# EMCAD Segmentation Model Training\n",
    "\n",
    "This notebook demonstrates how to train an EMCAD (Efficient Multi-scale Context Aggregation Decoder) model for image segmentation with a custom dataset structured as:\n",
    "\n",
    "- train/images - Contains training images\n",
    "- train/masks - Contains corresponding segmentation masks\n",
    "- test - Contains test images for submission (no masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0cb41b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from lib.networks import EMCADNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf1149",
   "metadata": {},
   "source": [
    "## 2. Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01699e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_root': './',  # Update this to your data directory\n",
    "    'train_image_path': 'train/images',\n",
    "    'train_mask_path': 'train/masks',\n",
    "    'test_image_path': 'test',\n",
    "    'img_size': 512,\n",
    "    'batch_size': 8,\n",
    "    'num_workers': 4,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 50,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'num_classes': 1,  # Binary segmentation (foreground vs background)\n",
    "    'encoder': 'resnet34',  # Use resnet34 as backbone\n",
    "    'pretrain': True,\n",
    "    'supervision': 'deep_supervision',  # Options: 'deep_supervision', 'mutation'\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967af69",
   "metadata": {},
   "source": [
    "## 3. Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cef043",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_paths, mask_paths=None, transform=None, is_test=False):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if not self.is_test:\n",
    "            # Load mask\n",
    "            mask_path = self.mask_paths[idx]\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # Apply transformations\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=img, mask=mask)\n",
    "                img = augmented['image']\n",
    "                mask = augmented['mask']\n",
    "            \n",
    "            # Convert mask to tensor and ensure correct shape\n",
    "            if isinstance(mask, np.ndarray):\n",
    "                mask = torch.from_numpy(mask).float()\n",
    "            mask = mask.unsqueeze(0)  # Add channel dimension\n",
    "            \n",
    "            return {\n",
    "                'image': img,\n",
    "                'mask': mask,\n",
    "                'filename': os.path.basename(img_path)\n",
    "            }\n",
    "        else:\n",
    "            # Test set (no masks)\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=img)\n",
    "                img = augmented['image']\n",
    "            \n",
    "            return {\n",
    "                'image': img,\n",
    "                'filename': os.path.basename(img_path)\n",
    "            }\n",
    "\n",
    "# Define transformations\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# Set up datasets and dataloaders\n",
    "def get_data_loaders():\n",
    "    # Get file paths\n",
    "    train_img_paths = sorted(glob(os.path.join(CONFIG['data_root'], CONFIG['train_image_path'], '*')))\n",
    "    train_mask_paths = sorted(glob(os.path.join(CONFIG['data_root'], CONFIG['train_mask_path'], '*')))\n",
    "    test_img_paths = sorted(glob(os.path.join(CONFIG['data_root'], CONFIG['test_image_path'], '*')))\n",
    "    \n",
    "    # Verify matching number of images and masks\n",
    "    assert len(train_img_paths) == len(train_mask_paths), \"Number of training images and masks don't match!\"\n",
    "    print(f\"Found {len(train_img_paths)} training images and {len(test_img_paths)} test images\")\n",
    "    \n",
    "    # Split train/val\n",
    "    val_split = 0.1\n",
    "    indices = np.arange(len(train_img_paths))\n",
    "    np.random.shuffle(indices)\n",
    "    val_size = int(len(train_img_paths) * val_split)\n",
    "    train_indices = indices[val_size:]\n",
    "    val_indices = indices[:val_size]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = SegmentationDataset(\n",
    "        [train_img_paths[i] for i in train_indices],\n",
    "        [train_mask_paths[i] for i in train_indices],\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = SegmentationDataset(\n",
    "        [train_img_paths[i] for i in val_indices],\n",
    "        [train_mask_paths[i] for i in val_indices],\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = SegmentationDataset(\n",
    "        test_img_paths,\n",
    "        transform=test_transform,\n",
    "        is_test=True\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders()\n",
    "\n",
    "# Visualize some samples\n",
    "def visualize_batch(dataloader):\n",
    "    batch = next(iter(dataloader))\n",
    "    images = batch['image']\n",
    "    if 'mask' in batch:\n",
    "        masks = batch['mask']\n",
    "        fig, axes = plt.subplots(4, 2, figsize=(12, 15))\n",
    "        for i in range(4):\n",
    "            if i < len(images):\n",
    "                # Display image\n",
    "                img = images[i].permute(1, 2, 0).numpy()\n",
    "                img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "                img = np.clip(img, 0, 1)\n",
    "                axes[i, 0].imshow(img)\n",
    "                axes[i, 0].set_title(f\"Image: {batch['filename'][i]}\")\n",
    "                \n",
    "                # Display mask\n",
    "                axes[i, 1].imshow(masks[i][0].numpy(), cmap='gray')\n",
    "                axes[i, 1].set_title(\"Mask\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        axes = axes.flatten()\n",
    "        for i in range(4):\n",
    "            if i < len(images):\n",
    "                img = images[i].permute(1, 2, 0).numpy()\n",
    "                img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "                img = np.clip(img, 0, 1)\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f\"Test Image: {batch['filename'][i]}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"Visualizing training samples:\")\n",
    "visualize_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5af02b",
   "metadata": {},
   "source": [
    "## 4. Define Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DiceLoss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred = pred.contiguous().view(-1)\n",
    "        target = target.contiguous().view(-1)\n",
    "        \n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "# Define IoU (Jaccard) metric\n",
    "def iou_score(pred, target):\n",
    "    pred = torch.sigmoid(pred) > 0.5\n",
    "    pred = pred.view(-1).float()\n",
    "    target = target.view(-1).float()\n",
    "    \n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    \n",
    "    return (intersection + 1e-7) / (union + 1e-7)\n",
    "\n",
    "# Define BCE-Dice combined loss\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, weight_bce=0.5, weight_dice=0.5):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "        self.weight_bce = weight_bce\n",
    "        self.weight_dice = weight_dice\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        bce_loss = self.bce(pred, target)\n",
    "        dice_loss = self.dice(pred, target)\n",
    "        loss = self.weight_bce * bce_loss + self.weight_dice * dice_loss\n",
    "        return loss\n",
    "\n",
    "# Function to gather all supervision outputs from powerset\n",
    "def powerset(iterable):\n",
    "    \"\"\"Returns the powerset of an iterable except the empty set.\"\"\"\n",
    "    from itertools import chain, combinations\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f60e57",
   "metadata": {},
   "source": [
    "## 5. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMCAD model\n",
    "model = EMCADNet(\n",
    "    num_classes=CONFIG['num_classes'], \n",
    "    encoder=CONFIG['encoder'], \n",
    "    pretrain=CONFIG['pretrain'],\n",
    "    kernel_sizes=[1, 3, 5],\n",
    "    expansion_factor=2,\n",
    "    dw_parallel=True,\n",
    "    add=True\n",
    ").to(CONFIG['device'])\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Define loss function\n",
    "criterion = BCEDiceLoss(weight_bce=0.5, weight_dice=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cd666",
   "metadata": {},
   "source": [
    "## 6. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e1cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    best_iou = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_iou': []}\n",
    "\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, total=len(train_loader), desc=f\"Training\")\n",
    "        for batch in train_pbar:\n",
    "            images = batch['image'].to(CONFIG['device'])\n",
    "            masks = batch['mask'].to(CONFIG['device'])\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images, mode='train')\n",
    "            \n",
    "            # Loss calculation based on supervision strategy\n",
    "            if not isinstance(outputs, list):\n",
    "                outputs = [outputs]\n",
    "            \n",
    "            if epoch == 0 and batch == next(iter(train_loader)):\n",
    "                n_outs = len(outputs)\n",
    "                out_idxs = list(np.arange(n_outs))\n",
    "                if CONFIG['supervision'] == 'mutation':\n",
    "                    ss = [x for x in powerset(out_idxs)]\n",
    "                elif CONFIG['supervision'] == 'deep_supervision':\n",
    "                    ss = [[x] for x in out_idxs]\n",
    "                else:  # Normal supervision (use only final output)\n",
    "                    ss = [[-1]]\n",
    "                print(f\"Using supervision strategy: {CONFIG['supervision']}\")\n",
    "                print(f\"Output indices: {ss}\")\n",
    "            \n",
    "            loss = 0.0\n",
    "            for s in ss:\n",
    "                if s == []:\n",
    "                    continue\n",
    "                    \n",
    "                iout = 0.0\n",
    "                for idx in range(len(s)):\n",
    "                    iout += outputs[s[idx]]\n",
    "                \n",
    "                loss += criterion(iout, masks)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_iou = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, total=len(val_loader), desc=f\"Validation\")\n",
    "            for batch in val_pbar:\n",
    "                images = batch['image'].to(CONFIG['device'])\n",
    "                masks = batch['mask'].to(CONFIG['device'])\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images, mode='test')\n",
    "                \n",
    "                # Use final output for validation metrics\n",
    "                final_output = outputs[0]\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(final_output, masks)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Calculate IoU\n",
    "                batch_iou = iou_score(final_output, masks)\n",
    "                val_iou += batch_iou.item()\n",
    "                \n",
    "                val_pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'iou': f\"{batch_iou.item():.4f}\"})\n",
    "                \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_iou = val_iou / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_iou'].append(avg_val_iou)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val IoU: {avg_val_iou:.4f}, LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_iou > best_iou:\n",
    "            best_iou = avg_val_iou\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_iou': best_iou,\n",
    "            }, 'best_model_emcad.pth')\n",
    "            print(f\"Best model saved with IoU: {best_iou:.4f}\")\n",
    "            \n",
    "        # Save checkpoint every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_iou': avg_val_iou,\n",
    "            }, f'checkpoint_emcad_epoch{epoch+1}.pth')\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss History')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['val_iou'], label='Val IoU')\n",
    "    plt.legend()\n",
    "    plt.title('IoU History')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "history = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f11d2",
   "metadata": {},
   "source": [
    "## 7. Inference and Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8575d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for inference\n",
    "def load_best_model():\n",
    "    checkpoint = torch.load('best_model_emcad.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model with validation IoU: {checkpoint['val_iou']:.4f}\")\n",
    "    return model\n",
    "\n",
    "model = load_best_model()\n",
    "model.eval()\n",
    "\n",
    "# Function to create RLE encoding for Kaggle submission\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# Make predictions on test set\n",
    "def predict_test_set():\n",
    "    submission = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pbar = tqdm(test_loader, total=len(test_loader), desc=\"Generating predictions\")\n",
    "        for batch in test_pbar:\n",
    "            images = batch['image'].to(CONFIG['device'])\n",
    "            filenames = batch['filename']\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(images, mode='test')\n",
    "            final_output = outputs[0]\n",
    "            \n",
    "            # Apply sigmoid and threshold\n",
    "            preds = torch.sigmoid(final_output) > 0.5\n",
    "            \n",
    "            # Process each image in the batch\n",
    "            for i, filename in enumerate(filenames):\n",
    "                # Convert prediction to numpy and resize to original size if needed\n",
    "                pred = preds[i].squeeze().cpu().numpy().astype(np.uint8)\n",
    "                \n",
    "                # Create RLE encoding\n",
    "                rle = rle_encode(pred)\n",
    "                \n",
    "                # Add to submission list\n",
    "                submission.append([filename, rle])\n",
    "    \n",
    "    # Create submission CSV\n",
    "    import pandas as pd\n",
    "    submission_df = pd.DataFrame(submission, columns=['id', 'rle_mask'])\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file created: submission.csv\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Generate predictions and create submission\n",
    "submission_df = predict_test_set()\n",
    "\n",
    "# Display a few test predictions\n",
    "def visualize_test_predictions():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(test_loader))\n",
    "        images = batch['image'].to(CONFIG['device'])\n",
    "        filenames = batch['filename']\n",
    "        \n",
    "        outputs = model(images, mode='test')\n",
    "        final_output = outputs[0]\n",
    "        preds = torch.sigmoid(final_output) > 0.5\n",
    "        \n",
    "        fig, axes = plt.subplots(len(images), 2, figsize=(12, 4*len(images)))\n",
    "        if len(images) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "            \n",
    "        for i in range(len(images)):\n",
    "            # Display original image\n",
    "            img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "            img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "            img = np.clip(img, 0, 1)\n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title(f\"Image: {filenames[i]}\")\n",
    "            \n",
    "            # Display prediction\n",
    "            axes[i, 1].imshow(preds[i].squeeze().cpu().numpy(), cmap='gray')\n",
    "            axes[i, 1].set_title(\"Prediction\")\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "visualize_test_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3bc85a",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "We've successfully:\n",
    "1. Loaded and preprocessed the custom segmentation dataset\n",
    "2. Trained the EMCAD model with different supervision strategies\n",
    "3. Evaluated the model using IoU metric\n",
    "4. Generated predictions for the test set and created a submission file for Kaggle\n",
    "\n",
    "The best model has been saved as `best_model_emcad.pth` and can be used for future inference."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
