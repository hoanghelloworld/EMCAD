{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b866c670",
   "metadata": {},
   "source": [
    "# EMCAD Training for Binary Segmentation\n",
    "\n",
    "This notebook demonstrates how to use EMCAD architecture for binary segmentation (0/255 masks).\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "# Import necessary modules from EMCAD\n",
    "from lib.networks import EMCADNet\n",
    "from utils.utils import DiceLoss, AvgMeter\n",
    "\n",
    "# For reproducibility\n",
    "seed = 2222\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f0609",
   "metadata": {},
   "source": [
    "## Dataset Class for Binary Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarySegmentationDataset(Dataset):\n",
    "    def __init__(self, image_root, mask_root=None, trainsize=224, is_train=True, augmentations=True):\n",
    "        self.trainsize = trainsize\n",
    "        self.is_train = is_train\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "        # Get image paths\n",
    "        self.images = sorted(glob(os.path.join(image_root, '*')))\n",
    "        \n",
    "        # Get mask paths if this is training data\n",
    "        if mask_root is not None:\n",
    "            self.masks = sorted(glob(os.path.join(mask_root, '*')))\n",
    "            assert len(self.images) == len(self.masks), \"Number of images and masks don't match\"\n",
    "        else:\n",
    "            self.masks = None\n",
    "        \n",
    "        print(f\"Found {len(self.images)} images\")\n",
    "        if self.masks:\n",
    "            print(f\"Found {len(self.masks)} masks\")\n",
    "        \n",
    "        # Define transforms\n",
    "        if self.augmentations and is_train:\n",
    "            print('Using data augmentations')\n",
    "            self.img_transform = transforms.Compose([\n",
    "                transforms.RandomRotation(30),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.Resize((self.trainsize, self.trainsize)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            \n",
    "            self.mask_transform = transforms.Compose([\n",
    "                transforms.RandomRotation(30),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.Resize((self.trainsize, self.trainsize)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            print('No data augmentation')\n",
    "            self.img_transform = transforms.Compose([\n",
    "                transforms.Resize((self.trainsize, self.trainsize)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            \n",
    "            self.mask_transform = transforms.Compose([\n",
    "                transforms.Resize((self.trainsize, self.trainsize)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Load image\n",
    "        img_path = self.images[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms with same seed for synchronized transforms\n",
    "        if self.masks is not None:\n",
    "            # Load mask\n",
    "            mask_path = self.masks[index]\n",
    "            mask = Image.open(mask_path).convert('L')  # Convert to grayscale\n",
    "            \n",
    "            # Apply the same transformation to both image and mask\n",
    "            seed = np.random.randint(2147483647)\n",
    "            \n",
    "            random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            img = self.img_transform(img)\n",
    "            \n",
    "            random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            mask = self.mask_transform(mask)\n",
    "            \n",
    "            # Convert mask to binary - threshold at 0.5 (128/255)\n",
    "            mask = (mask > 0.5).float()\n",
    "            \n",
    "            return img, mask, os.path.basename(img_path)\n",
    "        else:\n",
    "            # For test set without masks\n",
    "            img = self.img_transform(img)\n",
    "            return img, os.path.basename(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df104d",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151406a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "img_size = 224  # EMCAD default is 224\n",
    "batch_size = 8\n",
    "num_classes = 2  # Binary segmentation: background and foreground\n",
    "data_dir = '/path/to/your/data'  # Replace with your data path\n",
    "train_img_dir = os.path.join(data_dir, 'train/images')\n",
    "train_mask_dir = os.path.join(data_dir, 'train/masks')\n",
    "test_img_dir = os.path.join(data_dir, 'test')\n",
    "result_dir = './results'\n",
    "model_dir = './model_checkpoints'\n",
    "\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Model parameters\n",
    "encoder = 'pvt_v2_b2'  # Default EMCAD encoder\n",
    "kernel_sizes = [1, 3, 5]  # Default EMCAD kernel sizes\n",
    "expansion_factor = 2\n",
    "lgag_ks = 3\n",
    "activation_mscb = 'relu6'\n",
    "supervision = 'mutation'\n",
    "pretrained_dir = './pretrained_pth/pvt/'\n",
    "\n",
    "# Split data into train and validation\n",
    "all_images = sorted(glob(os.path.join(train_img_dir, '*')))\n",
    "all_masks = sorted(glob(os.path.join(train_mask_dir, '*')))\n",
    "\n",
    "# Use 85% data for training, 15% for validation\n",
    "train_size = int(0.85 * len(all_images))\n",
    "val_size = len(all_images) - train_size\n",
    "\n",
    "train_img_list = all_images[:train_size]\n",
    "val_img_list = all_images[train_size:]\n",
    "train_mask_list = all_masks[:train_size]\n",
    "val_mask_list = all_masks[train_size:]\n",
    "\n",
    "print(f\"Training samples: {len(train_img_list)}\")\n",
    "print(f\"Validation samples: {len(val_img_list)}\")\n",
    "\n",
    "# Create temporary directories for train/val split\n",
    "os.makedirs('./tmp/train/images', exist_ok=True)\n",
    "os.makedirs('./tmp/train/masks', exist_ok=True)\n",
    "os.makedirs('./tmp/val/images', exist_ok=True)\n",
    "os.makedirs('./tmp/val/masks', exist_ok=True)\n",
    "\n",
    "# Copy files to temporary directories (or create symlinks)\n",
    "import shutil\n",
    "# Uncomment below code if you want to physically copy files\n",
    "\n",
    "'''\n",
    "for img_path in train_img_list:\n",
    "    shutil.copy(img_path, os.path.join('./tmp/train/images', os.path.basename(img_path)))\n",
    "\n",
    "for mask_path in train_mask_list:\n",
    "    shutil.copy(mask_path, os.path.join('./tmp/train/masks', os.path.basename(mask_path)))\n",
    "    \n",
    "for img_path in val_img_list:\n",
    "    shutil.copy(img_path, os.path.join('./tmp/val/images', os.path.basename(img_path)))\n",
    "    \n",
    "for mask_path in val_mask_list:\n",
    "    shutil.copy(mask_path, os.path.join('./tmp/val/masks', os.path.basename(mask_path)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b889c8",
   "metadata": {},
   "source": [
    "## Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff979eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = BinarySegmentationDataset(\n",
    "    image_root='./tmp/train/images',\n",
    "    mask_root='./tmp/train/masks',\n",
    "    trainsize=img_size,\n",
    "    is_train=True,\n",
    "    augmentations=True\n",
    ")\n",
    "\n",
    "val_dataset = BinarySegmentationDataset(\n",
    "    image_root='./tmp/val/images',\n",
    "    mask_root='./tmp/val/masks',\n",
    "    trainsize=img_size,\n",
    "    is_train=False,\n",
    "    augmentations=False\n",
    ")\n",
    "\n",
    "test_dataset = BinarySegmentationDataset(\n",
    "    image_root=test_img_dir,\n",
    "    mask_root=None,\n",
    "    trainsize=img_size,\n",
    "    is_train=False,\n",
    "    augmentations=False\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af29ff2",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219812f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(images, masks, predictions=None, num_samples=4):\n",
    "    \"\"\"Visualize a batch of images, masks and predictions\"\"\"\n",
    "    plt.figure(figsize=(15, 5 * min(num_samples, len(images))))\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Convert tensors to numpy arrays\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        mask = masks[i].cpu().squeeze().numpy()\n",
    "        \n",
    "        # Display original image\n",
    "        plt.subplot(min(num_samples, len(images)), 3, i*3 + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Image {i+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Display ground truth mask\n",
    "        plt.subplot(min(num_samples, len(images)), 3, i*3 + 2)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.title(f\"Ground Truth {i+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if predictions is not None:\n",
    "            pred = predictions[i].cpu().squeeze().numpy()\n",
    "            \n",
    "            # Display prediction\n",
    "            plt.subplot(min(num_samples, len(images)), 3, i*3 + 3)\n",
    "            plt.imshow(pred, cmap='gray')\n",
    "            plt.title(f\"Prediction {i+1}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test visualization with a batch from validation set\n",
    "val_batch = next(iter(val_loader))\n",
    "visualize_batch(val_batch[0], val_batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76944301",
   "metadata": {},
   "source": [
    "## Initialize the EMCAD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize EMCAD model for binary segmentation\n",
    "model = EMCADNet(\n",
    "    num_classes=num_classes,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    expansion_factor=expansion_factor,\n",
    "    dw_parallel=True,  # Default setting\n",
    "    add=True,  # Default setting: use addition instead of concatenation\n",
    "    lgag_ks=lgag_ks,\n",
    "    activation=activation_mscb,\n",
    "    encoder=encoder,\n",
    "    pretrain=True,  # Use pretrained weights\n",
    "    pretrained_dir=pretrained_dir\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss functions\n",
    "dice_loss = DiceLoss(num_classes)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.1, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "print(\"Model initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee7cc6",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44888c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    dice_meter = AvgMeter()\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for images, masks, _ in progress_bar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, mode='train')\n",
    "        \n",
    "        # Handle multiple outputs from the model\n",
    "        if isinstance(outputs, list):\n",
    "            loss = 0.0\n",
    "            w_ce, w_dice = 0.3, 0.7  # Loss weights\n",
    "            \n",
    "            for output in outputs:\n",
    "                # Cross entropy loss - masks should be long type with class indices\n",
    "                targets = masks.squeeze(1).long()\n",
    "                loss_ce = ce_loss(output, targets)\n",
    "                loss_dice = dice_loss(output, targets, softmax=True)\n",
    "                loss += w_ce * loss_ce + w_dice * loss_dice\n",
    "                \n",
    "            loss = loss / len(outputs)  # Average over outputs\n",
    "        else:\n",
    "            # Single output\n",
    "            targets = masks.squeeze(1).long()\n",
    "            loss_ce = ce_loss(outputs, targets)\n",
    "            loss_dice = dice_loss(outputs, targets, softmax=True)\n",
    "            loss = w_ce * loss_ce + w_dice * loss_dice\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Get the final predictions for calculating metrics\n",
    "        if isinstance(outputs, list):\n",
    "            final_output = outputs[-1]\n",
    "        else:\n",
    "            final_output = outputs\n",
    "        \n",
    "        # Get the prediction\n",
    "        probs = torch.softmax(final_output, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).unsqueeze(1)\n",
    "        \n",
    "        # Calculate Dice score\n",
    "        dice = 1 - dice_loss._dice_loss(preds.float(), masks)\n",
    "        dice_meter.update(dice.item())\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix(loss=loss.item(), dice=dice_meter.avg)\n",
    "    \n",
    "    return total_loss / len(train_loader), dice_meter.avg\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    dice_meter = AvgMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Validation\")\n",
    "        \n",
    "        for images, masks, _ in progress_bar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get the final predictions if multiple outputs\n",
    "            if isinstance(outputs, list):\n",
    "                outputs = outputs[-1]\n",
    "            \n",
    "            # Calculate loss\n",
    "            targets = masks.squeeze(1).long()\n",
    "            loss_ce = ce_loss(outputs, targets)\n",
    "            loss_dice = dice_loss(outputs, targets, softmax=True)\n",
    "            loss = 0.3 * loss_ce + 0.7 * loss_dice\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get the prediction\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1).unsqueeze(1)\n",
    "            \n",
    "            # Calculate Dice score\n",
    "            dice = 1 - dice_loss._dice_loss(preds.float(), masks)\n",
    "            dice_meter.update(dice.item())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix(loss=loss.item(), dice=dice_meter.avg)\n",
    "    \n",
    "    return total_loss / len(val_loader), dice_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_dice = 0.0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_dices = []\n",
    "val_dices = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss, train_dice = train_epoch(model, train_loader, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_dices.append(train_dice)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice = validate(model, val_loader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_dices.append(val_dice)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}\")\n",
    "    \n",
    "    # Update learning rate based on validation dice score\n",
    "    scheduler.step(val_dice)\n",
    "    \n",
    "    # Save model if validation dice improves\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        print(f\"New best validation Dice: {best_dice:.4f}\")\n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'best_model.pth'))\n",
    "        print(\"Saved best model checkpoint\")\n",
    "    \n",
    "    # Save model at each epoch\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_dice': train_dice,\n",
    "        'val_dice': val_dice,\n",
    "    }, os.path.join(model_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "\n",
    "# Plot training and validation metrics\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_dices, label='Train Dice')\n",
    "plt.plot(val_dices, label='Val Dice')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(result_dir, 'training_metrics.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650cb05",
   "metadata": {},
   "source": [
    "## Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b310b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = os.path.join(model_dir, 'best_model.pth')\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Get some random validation samples\n",
    "val_iter = iter(val_loader)\n",
    "val_batch = next(val_iter)\n",
    "images, masks, _ = val_batch\n",
    "images = images.to(device)\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    if isinstance(outputs, list):\n",
    "        outputs = outputs[-1]\n",
    "    \n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1).unsqueeze(1)\n",
    "\n",
    "# Visualize results\n",
    "visualize_batch(images, masks, preds)\n",
    "\n",
    "# Calculate metrics on the entire validation set\n",
    "val_loss, val_dice = validate(model, val_loader, device)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Dice: {val_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c2aeb",
   "metadata": {},
   "source": [
    "## Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, test_loader, device, output_dir):\n",
    "    \"\"\"Generate and save predictions for the test set\"\"\"\n",
    "    model.eval()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, filenames in tqdm(test_loader, desc=\"Generating predictions\"):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get the final predictions if multiple outputs\n",
    "            if isinstance(outputs, list):\n",
    "                outputs = outputs[-1]\n",
    "            \n",
    "            # Generate binary predictions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            # Save each prediction\n",
    "            for i, filename in enumerate(filenames):\n",
    "                pred_mask = preds[i].cpu().numpy() * 255  # Convert back to 0-255 range\n",
    "                cv2.imwrite(os.path.join(output_dir, filename), pred_mask.astype(np.uint8))\n",
    "\n",
    "# Create directory for test predictions\n",
    "test_output_dir = os.path.join(result_dir, 'test_predictions')\n",
    "os.makedirs(test_output_dir, exist_ok=True)\n",
    "\n",
    "# Generate predictions\n",
    "generate_predictions(model, test_loader, device, test_output_dir)\n",
    "print(f\"Test predictions saved to {test_output_dir}\")\n",
    "\n",
    "# Prepare for Kaggle submission if needed\n",
    "def prepare_kaggle_submission(test_output_dir, submission_file):\n",
    "    \"\"\"Prepare submission file for Kaggle\"\"\"\n",
    "    # This function depends on the specific Kaggle competition format\n",
    "    # You may need to adjust this based on your competition's requirements\n",
    "    \n",
    "    # Example: Create a simple CSV with filename and predicted class\n",
    "    import csv\n",
    "    \n",
    "    with open(submission_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'predicted'])  # Header\n",
    "        \n",
    "        for filename in os.listdir(test_output_dir):\n",
    "            # Read prediction\n",
    "            pred = cv2.imread(os.path.join(test_output_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # Process according to submission requirements\n",
    "            # This is just an example - adjust based on your specific needs\n",
    "            pred_value = 1 if np.mean(pred) > 127 else 0\n",
    "            \n",
    "            # Write to CSV\n",
    "            writer.writerow([filename.split('.')[0], pred_value])\n",
    "\n",
    "# Create Kaggle submission file\n",
    "submission_file = os.path.join(result_dir, 'submission.csv')\n",
    "# Uncomment the line below if you want to create the submission file\n",
    "# prepare_kaggle_submission(test_output_dir, submission_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb03a50",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "If you created temporary directories, you might want to clean them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab618db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary directories\n",
    "import shutil\n",
    "\n",
    "# Uncomment if you want to remove the temporary directories\n",
    "# shutil.rmtree('./tmp', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528ddf7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have successfully:\n",
    "1. Prepared your data for training with EMCAD\n",
    "2. Trained an EMCAD model for binary segmentation\n",
    "3. Evaluated the model on validation data\n",
    "4. Generated predictions for test data that can be submitted to Kaggle\n",
    "\n",
    "To improve results, consider:\n",
    "- Experimenting with different data augmentations\n",
    "- Trying different hyperparameters (learning rate, batch size)\n",
    "- Using different encoders (e.g., pvt_v2_b0, resnet34, etc.)\n",
    "- Implementing cross-validation to get more stable results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
